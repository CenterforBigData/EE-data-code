{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "116a2812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1. Complete Decomposition Using CEEMDAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b539f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyEMD import CEEMDAN\n",
    "\n",
    "# Load the dataset from an Excel file\n",
    "data = pd.read_excel('./Datasets/Original Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43861753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset to include only the training data based on the 'time_idx'\n",
    "train_data = data[data['time_idx'] <= 712]\n",
    "wti_train = train_data['WTI']\n",
    "brent_train = train_data['Brent']\n",
    "\n",
    "# Initialize the CEEMDAN object with a specified number of trials for robust decomposition\n",
    "ceemdan = CEEMDAN()\n",
    "ceemdan.trials = 100\n",
    "\n",
    "# Function to decompose a time series using the CEEMDAN method\n",
    "def decompose_data(series):\n",
    "    imfs = ceemdan(series)\n",
    "     # Calculate residuals by subtracting the sum of the first two IMFs from the original series if more than two IMFs are present\n",
    "    residual = series - sum(imfs[:2]) if len(imfs) > 2 else series - sum(imfs)\n",
    "    return imfs[:2], residual\n",
    "\n",
    "# Decompose the WTI and Brent training datasets\n",
    "wti_imfs, wti_residual = decompose_data(wti_train.values)\n",
    "brent_imfs, brent_residual = decompose_data(brent_train.values)\n",
    "\n",
    "# Append decomposed components to the original dataset and adjust by adding 10 for normalization\n",
    "# The addition of 10 to the first two IMFs (Intrinsic Mode Functions) is a preprocessing step to normalize their scale.\n",
    "# Since IMFs often oscillate around zero, this shift facilitates better learning and training stability for subsequent modeling.\n",
    "# This normalization is reversed in the final analysis to maintain the original data scale.\n",
    "for i, imf in enumerate(wti_imfs):\n",
    "    data[f'WTI_IMF{i+1}'] = pd.Series(imf + 10, index=train_data.index) # Adjust WTI IMFs\n",
    "data['WTI_Res'] = pd.Series(wti_residual, index=train_data.index) # Append WTI residual\n",
    "\n",
    "for i, imf in enumerate(brent_imfs):\n",
    "    data[f'Brent_IMF{i+1}'] = pd.Series(imf + 10, index=train_data.index)\n",
    "data['Brent_Res'] = pd.Series(brent_residual, index=train_data.index)\n",
    "\n",
    "# Save the enriched dataset back to the Excel file\n",
    "data.to_excel('./Datasets/Original Data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13b9457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 Extended Window Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a588f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('./Datasets/CEEMDAN Decomposed Data.xlsx')\n",
    "\n",
    "# Filter data for training based on the 'time_idx'\n",
    "train_data = data[data['time_idx'] <= 712]\n",
    "N1 = 30  # Main window size for feature extraction\n",
    "N2 = 5   # Extension window size\n",
    "\n",
    "mapping_pairs = []\n",
    "for t in range(1, len(train_data) - N1 - N2 + 1):\n",
    "    W_t = train_data.iloc[t-1:t+N1-1]  # Extract the main window data for past N1 days\n",
    "    D_k_t_plus_N2 = train_data.iloc[t+N2-1:t+N1+N2-1]  # Extract the extended window data for target IMF components at N2 days ahead\n",
    "\n",
    "    W_t_data = W_t[['WTI', 'time_idx']]\n",
    "    D_k_data = D_k_t_plus_N2[['WTI_IMF1', 'WTI_IMF2', 'WTI_Res']]\n",
    "    \n",
    "    # Collect the pair of feature matrix and target matrix for training\n",
    "    mapping_pairs.append((W_t_data, D_k_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75e63305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 Training the Enhancing Mapping Neural Network (EMNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6988e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "247f118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features size: (677, 60)\n",
      "Target IMF1 size: (677, 1)\n",
      "Target IMF2 size: (677, 1)\n",
      "Target Residual size: (677, 1)\n",
      "Epoch 1/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 39613.5195\n",
      "Epoch 1: loss improved from inf to 39321.37891, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 2s 35ms/step - loss: 39321.3789\n",
      "Epoch 2/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 24.8974\n",
      "Epoch 2: loss improved from 39321.37891 to 24.76466, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 24.7647\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.0262\n",
      "Epoch 3: loss improved from 24.76466 to 3.02620, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 1s 37ms/step - loss: 3.0262\n",
      "Epoch 4/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.6288\n",
      "Epoch 4: loss improved from 3.02620 to 2.65073, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 2.6507\n",
      "Epoch 5/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.9986\n",
      "Epoch 5: loss did not improve from 2.65073\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 2.9907\n",
      "Epoch 6/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 2.3526\n",
      "Epoch 6: loss improved from 2.65073 to 2.39825, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 2.3983\n",
      "Epoch 7/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.6422\n",
      "Epoch 7: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 2.6322\n",
      "Epoch 8/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.8611\n",
      "Epoch 8: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 3.8434\n",
      "Epoch 9/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.6674\n",
      "Epoch 9: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 3.6589\n",
      "Epoch 10/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.2732\n",
      "Epoch 10: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 3.2842\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.9847\n",
      "Epoch 11: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 3.9847\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.5474\n",
      "Epoch 12: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 2.5474\n",
      "Epoch 13/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.1781\n",
      "Epoch 13: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 3.2068\n",
      "Epoch 14/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.3319\n",
      "Epoch 14: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.3619\n",
      "Epoch 15/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.8819\n",
      "Epoch 15: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 2.8855\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.5846\n",
      "Epoch 16: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 2.5846\n",
      "Epoch 17/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.1450\n",
      "Epoch 17: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 3.1282\n",
      "Epoch 18/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.8717\n",
      "Epoch 18: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 2.8624\n",
      "Epoch 19/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.3279\n",
      "Epoch 19: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 3.3124\n",
      "Epoch 20/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.7897\n",
      "Epoch 20: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 5.7688\n",
      "Epoch 21/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.3051\n",
      "Epoch 21: loss did not improve from 2.39825\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 3.3027\n",
      "Epoch 22/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.3915\n",
      "Epoch 22: loss improved from 2.39825 to 2.38023, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 2.3802\n",
      "Epoch 23/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.5031\n",
      "Epoch 23: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 2.5171\n",
      "Epoch 24/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.6078\n",
      "Epoch 24: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 4.6306\n",
      "Epoch 25/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.9564\n",
      "Epoch 25: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 5.9688\n",
      "Epoch 26/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.3330\n",
      "Epoch 26: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.3612\n",
      "Epoch 27/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.8931\n",
      "Epoch 27: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.8714\n",
      "Epoch 28/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.5831\n",
      "Epoch 28: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 2.5857\n",
      "Epoch 29/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.4929\n",
      "Epoch 29: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 2.4904\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.8941\n",
      "Epoch 30: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 3.8941\n",
      "Epoch 31/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.9226\n",
      "Epoch 31: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 2.9280\n",
      "Epoch 32/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.2574\n",
      "Epoch 32: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 3.2498\n",
      "Epoch 33/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.9965\n",
      "Epoch 33: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 2.9956\n",
      "Epoch 34/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.4214\n",
      "Epoch 34: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 2.4112\n",
      "Epoch 35/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.4603\n",
      "Epoch 35: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 3.4453\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 5.2651\n",
      "Epoch 36: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 5.2651\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 4.9519\n",
      "Epoch 37: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.9519\n",
      "Epoch 38/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 7.1551\n",
      "Epoch 38: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 7.1524\n",
      "Epoch 39/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.2883\n",
      "Epoch 39: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 3.2700\n",
      "Epoch 40/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 3.0736\n",
      "Epoch 40: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 3.0928\n",
      "Epoch 41/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 9.1614\n",
      "Epoch 41: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 9.1059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.7903\n",
      "Epoch 42: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 2.8025\n",
      "Epoch 43/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 3.3608\n",
      "Epoch 43: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 3.3946\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.5894\n",
      "Epoch 44: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 2.5894\n",
      "Epoch 45/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.2081\n",
      "Epoch 45: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 4.1896\n",
      "Epoch 46/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.4323\n",
      "Epoch 46: loss did not improve from 2.38023\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 2.4416\n",
      "Epoch 47/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.3273\n",
      "Epoch 47: loss improved from 2.38023 to 2.32596, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 2.3260\n",
      "Epoch 48/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.3212\n",
      "Epoch 48: loss improved from 2.32596 to 2.32091, saving model to ./EEMD_saved_models\\WTI_imf1_best_model.h5\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 2.3209\n",
      "Epoch 49/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 2.5115\n",
      "Epoch 49: loss did not improve from 2.32091\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 2.5042\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.4791\n",
      "Epoch 50: loss did not improve from 2.32091\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 2.4791\n",
      "Epoch 1/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 25937.7207\n",
      "Epoch 1: loss improved from inf to 25747.10547, saving model to ./EEMD_saved_models\\WTI_imf2_best_model.h5\n",
      "22/22 [==============================] - 2s 34ms/step - loss: 25747.1055\n",
      "Epoch 2/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 39.0424\n",
      "Epoch 2: loss improved from 25747.10547 to 37.82123, saving model to ./EEMD_saved_models\\WTI_imf2_best_model.h5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 37.8212\n",
      "Epoch 3/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.3106\n",
      "Epoch 3: loss improved from 37.82123 to 5.29999, saving model to ./EEMD_saved_models\\WTI_imf2_best_model.h5\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 5.3000\n",
      "Epoch 4/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.5990\n",
      "Epoch 4: loss did not improve from 5.29999\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 5.5823\n",
      "Epoch 5/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.3597\n",
      "Epoch 5: loss did not improve from 5.29999\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 5.3388\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 5.3757\n",
      "Epoch 6: loss did not improve from 5.29999\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 5.3757\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 4.7765\n",
      "Epoch 7: loss improved from 5.29999 to 4.77647, saving model to ./EEMD_saved_models\\WTI_imf2_best_model.h5\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 4.7765\n",
      "Epoch 8/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.1469\n",
      "Epoch 8: loss did not improve from 4.77647\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 5.1164\n",
      "Epoch 9/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.8354\n",
      "Epoch 9: loss did not improve from 4.77647\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 4.8146\n",
      "Epoch 10/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.1788\n",
      "Epoch 10: loss did not improve from 4.77647\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 5.1545\n",
      "Epoch 11/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 6.7643\n",
      "Epoch 11: loss did not improve from 4.77647\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 6.7419\n",
      "Epoch 12/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.5860\n",
      "Epoch 12: loss improved from 4.77647 to 4.69999, saving model to ./EEMD_saved_models\\WTI_imf2_best_model.h5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 4.7000\n",
      "Epoch 13/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 6.2338\n",
      "Epoch 13: loss did not improve from 4.69999\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 6.1882\n",
      "Epoch 14/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.6235\n",
      "Epoch 14: loss did not improve from 4.69999\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 5.5901\n",
      "Epoch 15/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.4187\n",
      "Epoch 15: loss improved from 4.69999 to 4.40191, saving model to ./EEMD_saved_models\\WTI_imf2_best_model.h5\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 4.4019\n",
      "Epoch 16/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.2391\n",
      "Epoch 16: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 5.2604\n",
      "Epoch 17/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.2278\n",
      "Epoch 17: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 5.2107\n",
      "Epoch 18/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 7.1508\n",
      "Epoch 18: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 7.1266\n",
      "Epoch 19/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 9.3529\n",
      "Epoch 19: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 9.3364\n",
      "Epoch 20/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.6056\n",
      "Epoch 20: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 5.5975\n",
      "Epoch 21/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.7992\n",
      "Epoch 21: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 4.9293\n",
      "Epoch 22/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 8.9113\n",
      "Epoch 22: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 8.8741\n",
      "Epoch 23/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 6.2258\n",
      "Epoch 23: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 6.2046\n",
      "Epoch 24/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.6084\n",
      "Epoch 24: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 5.5836\n",
      "Epoch 25/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.9946\n",
      "Epoch 25: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 4.9869\n",
      "Epoch 26/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 6.1237\n",
      "Epoch 26: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 6.1096\n",
      "Epoch 27/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 6.8252\n",
      "Epoch 27: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 6.8047\n",
      "Epoch 28/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.7973\n",
      "Epoch 28: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 4.8081\n",
      "Epoch 29/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.9496\n",
      "Epoch 29: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.9316\n",
      "Epoch 30/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 5.7869\n",
      "Epoch 30: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 6.0706\n",
      "Epoch 31/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.0139\n",
      "Epoch 31: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 5.0346\n",
      "Epoch 32/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 4.6103\n",
      "Epoch 32: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 4.7385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.3983\n",
      "Epoch 33: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 4.5383\n",
      "Epoch 34/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.0100\n",
      "Epoch 34: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.9879\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 4.7025\n",
      "Epoch 35: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 4.7025\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 7.2521\n",
      "Epoch 36: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 7.2521\n",
      "Epoch 37/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.4934\n",
      "Epoch 37: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 5.4658\n",
      "Epoch 38/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.6743\n",
      "Epoch 38: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.6748\n",
      "Epoch 39/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.9055\n",
      "Epoch 39: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 4.8932\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 5.0830\n",
      "Epoch 40: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 5.0830\n",
      "Epoch 41/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.8518\n",
      "Epoch 41: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 4.8208\n",
      "Epoch 42/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.8806\n",
      "Epoch 42: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 4.8623\n",
      "Epoch 43/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.4691\n",
      "Epoch 43: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 5.4296\n",
      "Epoch 44/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.6502\n",
      "Epoch 44: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 5.6363\n",
      "Epoch 45/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 4.7099\n",
      "Epoch 45: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 4.6957\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 5.1153\n",
      "Epoch 46: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 5.1153\n",
      "Epoch 47/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 5.8990\n",
      "Epoch 47: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 5.9189\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 4.5639\n",
      "Epoch 48: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 4.5639\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 4.6450\n",
      "Epoch 49: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 4.6450\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 4.6754\n",
      "Epoch 50: loss did not improve from 4.40191\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 4.6754\n",
      "Epoch 1/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 37164.3203\n",
      "Epoch 1: loss improved from inf to 35140.85547, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 2s 33ms/step - loss: 35140.8555\n",
      "Epoch 2/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 49.0211\n",
      "Epoch 2: loss improved from 35140.85547 to 49.14853, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 49.1485\n",
      "Epoch 3/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 83.5618\n",
      "Epoch 3: loss did not improve from 49.14853\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 83.0843\n",
      "Epoch 4/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 76.7691\n",
      "Epoch 4: loss did not improve from 49.14853\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 76.8544\n",
      "Epoch 5/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 49.7847\n",
      "Epoch 5: loss did not improve from 49.14853\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 49.5341\n",
      "Epoch 6/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 37.6712\n",
      "Epoch 6: loss improved from 49.14853 to 37.56928, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 37.5693\n",
      "Epoch 7/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 50.7184\n",
      "Epoch 7: loss did not improve from 37.56928\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 51.0185\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 50.0962\n",
      "Epoch 8: loss did not improve from 37.56928\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 50.0962\n",
      "Epoch 9/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 76.6221\n",
      "Epoch 9: loss did not improve from 37.56928\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 76.5978\n",
      "Epoch 10/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 43.2814\n",
      "Epoch 10: loss did not improve from 37.56928\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 43.0746\n",
      "Epoch 11/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 30.2673\n",
      "Epoch 11: loss improved from 37.56928 to 31.22622, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 31.2262\n",
      "Epoch 12/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 79.4692\n",
      "Epoch 12: loss did not improve from 31.22622\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 79.2288\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 111.6351\n",
      "Epoch 13: loss did not improve from 31.22622\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 111.6351\n",
      "Epoch 14/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 57.3996\n",
      "Epoch 14: loss did not improve from 31.22622\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 57.1425\n",
      "Epoch 15/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 59.3735\n",
      "Epoch 15: loss did not improve from 31.22622\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 58.9929\n",
      "Epoch 16/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 29.0003\n",
      "Epoch 16: loss improved from 31.22622 to 28.97174, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 28.9717\n",
      "Epoch 17/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 32.3905\n",
      "Epoch 17: loss did not improve from 28.97174\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 32.4382\n",
      "Epoch 18/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 43.2683\n",
      "Epoch 18: loss did not improve from 28.97174\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 43.2919\n",
      "Epoch 19/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 34.8804\n",
      "Epoch 19: loss did not improve from 28.97174\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 34.6766\n",
      "Epoch 20/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 25.0916\n",
      "Epoch 20: loss improved from 28.97174 to 24.98680, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 24.9868\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 30.8130\n",
      "Epoch 21: loss did not improve from 24.98680\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 30.8130\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 25.0963\n",
      "Epoch 22: loss did not improve from 24.98680\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 25.0963\n",
      "Epoch 23/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 29.0932\n",
      "Epoch 23: loss did not improve from 24.98680\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 29.0320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 25.2745\n",
      "Epoch 24: loss did not improve from 24.98680\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 25.3073\n",
      "Epoch 25/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 25.2717\n",
      "Epoch 25: loss did not improve from 24.98680\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 25.3784\n",
      "Epoch 26/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 23.1350\n",
      "Epoch 26: loss improved from 24.98680 to 23.26049, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 23.2605\n",
      "Epoch 27/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 33.2620\n",
      "Epoch 27: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 33.2038\n",
      "Epoch 28/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 30.1483\n",
      "Epoch 28: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 30.0379\n",
      "Epoch 29/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 28.4133\n",
      "Epoch 29: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 28.5799\n",
      "Epoch 30/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 34.2974\n",
      "Epoch 30: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 34.1080\n",
      "Epoch 31/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 34.9015\n",
      "Epoch 31: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 35.3331\n",
      "Epoch 32/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 28.4867\n",
      "Epoch 32: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 28.5059\n",
      "Epoch 33/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 24.5160\n",
      "Epoch 33: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 24.6079\n",
      "Epoch 34/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 34.7555\n",
      "Epoch 34: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 34.6908\n",
      "Epoch 35/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 25.8681\n",
      "Epoch 35: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 25.7559\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 26.5644\n",
      "Epoch 36: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 26.5644\n",
      "Epoch 37/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 41.8328\n",
      "Epoch 37: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 41.6351\n",
      "Epoch 38/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 24.0406\n",
      "Epoch 38: loss did not improve from 23.26049\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 24.0439\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - ETA: 0s - loss: 21.8615\n",
      "Epoch 39: loss improved from 23.26049 to 21.86152, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 21.8615\n",
      "Epoch 40/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 23.4344\n",
      "Epoch 40: loss did not improve from 21.86152\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 23.3703\n",
      "Epoch 41/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 21.2593\n",
      "Epoch 41: loss improved from 21.86152 to 21.19263, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 21.1926\n",
      "Epoch 42/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 21.1577\n",
      "Epoch 42: loss improved from 21.19263 to 21.08530, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 21.0853\n",
      "Epoch 43/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 24.8568\n",
      "Epoch 43: loss did not improve from 21.08530\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 24.7729\n",
      "Epoch 44/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 29.2756\n",
      "Epoch 44: loss did not improve from 21.08530\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 29.1615\n",
      "Epoch 45/50\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 27.5387\n",
      "Epoch 45: loss did not improve from 21.08530\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 26.7449\n",
      "Epoch 46/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 26.7336\n",
      "Epoch 46: loss did not improve from 21.08530\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 26.7411\n",
      "Epoch 47/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 19.4779\n",
      "Epoch 47: loss improved from 21.08530 to 19.77309, saving model to ./EEMD_saved_models\\WTI_residual_best_model.h5\n",
      "22/22 [==============================] - 1s 30ms/step - loss: 19.7731\n",
      "Epoch 48/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 24.1233\n",
      "Epoch 48: loss did not improve from 19.77309\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 24.0747\n",
      "Epoch 49/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 30.8226\n",
      "Epoch 49: loss did not improve from 19.77309\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 30.8308\n",
      "Epoch 50/50\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 21.1926\n",
      "Epoch 50: loss did not improve from 19.77309\n",
      "22/22 [==============================] - 1s 29ms/step - loss: 21.1769\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define a function to build a multi-layer neural network model for regression\n",
    "def build_mnn_model(input_dim):\n",
    "    # Construct a fully connected neural network with four hidden layers and one output layer\n",
    "    model = Sequential([\n",
    "        Dense(1024, input_dim=input_dim, activation='relu'),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dense(1)   \n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse') # Compile model with MSE loss and Adam optimizer\n",
    "    return model\n",
    "\n",
    "# Extract features and targets for training from mapping pairs\n",
    "train_features = np.array([pair[0].values.flatten() for pair in mapping_pairs])\n",
    "train_targets_imf1 = np.array([pair[1]['WTI_IMF1'].values[-1] for pair in mapping_pairs]).reshape(-1, 1)\n",
    "train_targets_imf2 = np.array([pair[1]['WTI_IMF2'].values[-1] for pair in mapping_pairs]).reshape(-1, 1)\n",
    "train_targets_residual = np.array([pair[1]['WTI_Res'].values[-1] for pair in mapping_pairs]).reshape(-1, 1)\n",
    "\n",
    "# Build models for each IMF and the residual\n",
    "input_dim = W_t_data.shape[1] * W_t_data.shape[0]  \n",
    "imf1_model = build_mnn_model(input_dim)\n",
    "imf2_model = build_mnn_model(input_dim)\n",
    "residual_model = build_mnn_model(input_dim)\n",
    "\n",
    "# Configure callbacks to save the best model based on the lowest loss\n",
    "checkpoint_imf1 = ModelCheckpoint('./EEMD_saved_models/WTI_imf1_best_model.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "checkpoint_imf2 = ModelCheckpoint('./EEMD_saved_models/WTI_imf2_best_model.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "checkpoint_residual = ModelCheckpoint('./EEMD_saved_models/WTI_residual_best_model.h5', monitor='loss', save_best_only=True, verbose=1)\n",
    "\n",
    "# Conditionally train models if all data arrays match in length\n",
    "if (len(train_features) == len(train_targets_imf1) == len(train_targets_imf2) == len(train_targets_residual)):\n",
    "    imf1_model.fit(train_features, train_targets_imf1, epochs=50, batch_size=32, verbose=1, callbacks=[checkpoint_imf1])\n",
    "    imf2_model.fit(train_features, train_targets_imf2, epochs=50, batch_size=32, verbose=1, callbacks=[checkpoint_imf2])\n",
    "    residual_model.fit(train_features, train_targets_residual, epochs=50, batch_size=32, verbose=1, callbacks=[checkpoint_residual])\n",
    "else:\n",
    "    print(\"Error: Data cardinality mismatch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cf792ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 Prediction/Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "368864aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Predictions integrated and Excel file updated.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load trained models\n",
    "imf1_model = load_model('./EEMD_saved_models/WTI_imf1_best_model.h5')\n",
    "imf2_model = load_model('./EEMD_saved_models/WTI_imf2_best_model.h5')\n",
    "\n",
    "# Load data\n",
    "data = pd.read_excel('./Datasets/CEEMDAN Decomposed Data.xlsx')\n",
    "data.sort_values('time_idx', inplace=True)\n",
    "\n",
    "# Define prediction range\n",
    "start_time_idx = 713 \n",
    "end_time_idx = data['time_idx'].max() \n",
    "\n",
    "# Predict and update DataFrame\n",
    "for time_idx in range(start_time_idx, end_time_idx + 1):\n",
    "    target_idx = time_idx - 1\n",
    "\n",
    "    if target_idx >= 0:\n",
    "        window_data = data.iloc[time_idx - 30:time_idx][['WTI', 'time_idx']].values.flatten()\n",
    "        window_data = np.expand_dims(window_data, axis=0)\n",
    "\n",
    "        # Predict\n",
    "        predicted_imf1 = imf1_model.predict(window_data)  \n",
    "        predicted_imf2 = imf2_model.predict(window_data) \n",
    "\n",
    "        # Update DataFrame\n",
    "        data.at[target_idx, 'WTI_IMF1'] = predicted_imf1.flatten()[0]\n",
    "        data.at[target_idx, 'WTI_IMF2'] = predicted_imf2.flatten()[0]\n",
    "\n",
    "        # Calculate and adjust residual\n",
    "        if 'WTI' in data.columns:\n",
    "            predicted_residual = data.at[target_idx, 'WTI'] - (predicted_imf1.flatten()[0] + predicted_imf2.flatten()[0])\n",
    "            data.at[target_idx, 'WTI_Res'] = predicted_residual + 20  # Include +20 adjustment here\n",
    "\n",
    "# Save the updated DataFrame back to Excel\n",
    "data.to_excel('./Datasets/CEEMDAN Decomposed Data.xlsx', index=False)\n",
    "\n",
    "print(\"Predictions integrated and Excel file updated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03414763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
